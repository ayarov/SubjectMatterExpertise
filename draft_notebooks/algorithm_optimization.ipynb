{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.ensemble\n",
    "import seaborn as sns\n",
    "# allow plots to appear within the note\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __default_exclusion():\n",
    "    return ['page_id', 'page', 'category', 'user', 'label','content_token_edit_count_avg', 'content_token_vs_stop_words']\n",
    "\n",
    "def drop_columns_gm(columns):\n",
    "    drop_list = __generalized_model_exclusion()\n",
    "    drop_list.extend(columns)\n",
    "    return drop_list    \n",
    "\n",
    "def drop_columns_fm(columns):\n",
    "    drop_list = __full_model_exclusion()\n",
    "    drop_list.extend(columns)\n",
    "    return drop_list\n",
    "\n",
    "def __full_model_exclusion():\n",
    "    return __default_exclusion()\n",
    "\n",
    "def __generalized_model_exclusion():\n",
    "    exclusion = __default_exclusion()\n",
    "    exclusion.extend(['page_talk_edits',\n",
    "                        'tenure',\n",
    "                        'ns1_edit_dist',\n",
    "                        'ns2_edit_dist',\n",
    "                        'ns3_edit_dist',\n",
    "                        'ns4_edit_dist',\n",
    "                        'ns5_edit_dist',\n",
    "                        'ns6_edit_dist',\n",
    "                        'ns7_edit_dist',\n",
    "                        'ns8_edit_dist',\n",
    "                        'ns9_edit_dist',\n",
    "                        'ns10_edit_dist',\n",
    "                        'ns11_edit_dist',\n",
    "                        'ns12_edit_dist',\n",
    "                        'ns13_edit_dist',\n",
    "                        'ns14_edit_dist',\n",
    "                        'ns15_edit_dist',\n",
    "                        'total_edited_pages'])\n",
    "\n",
    "    \n",
    "    return exclusion\n",
    "    \n",
    "def get_metrics(classifier, x, y, cv):\n",
    "    results = cross_val_score(classifier, x, y, cv=cv)\n",
    "    \n",
    "    accuracy = results.mean()\n",
    "    precision = cross_val_score(classifier, x, y, scoring='precision', cv=cv).mean()\n",
    "    recall = cross_val_score(classifier, x, y, scoring='recall', cv=cv).mean()\n",
    "    f1 = cross_val_score(classifier, x, y, scoring='f1', cv=cv).mean()\n",
    "    roc_auc = cross_val_score(classifier, x, y, scoring='roc_auc', cv=cv).mean()\n",
    "\n",
    "    print(results)\n",
    "    print('Accuracy: %.3f%%' % accuracy)\n",
    "    print('Precision: %.3f%%' % precision) \n",
    "    print('Recall: %.3f%%' % recall)\n",
    "    print('F1: %.3f%%' % f1)\n",
    "    print('ROC AUC: %.3f%%' % roc_auc)\n",
    "    print('\\n')\n",
    "    return [accuracy, precision, recall, f1, roc_auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experts: 506\n",
      "Total non-experts: 514\n"
     ]
    }
   ],
   "source": [
    "# loading data (training set)\n",
    "df = pd.read_csv('data/new_train_data.csv', header=0)\n",
    "print('Total experts: {}'.format(len(df[df.label == 1])))\n",
    "print('Total non-experts: {}'.format(len(df[df.label == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = 160\n",
    "random_state = 123\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=random_state)\n",
    "model = XGBClassifier(objective='binary:logistic', seed=random_state, n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edit_type_a', 'edit_type_b', 'edit_type_c', 'edit_type_d', 'edit_type_e', 'edit_type_f', 'edit_type_g', 'edit_type_h', 'edit_type_i', 'edit_type_j', 'edit_type_k', 'edit_type_l', 'edit_type_m']\n"
     ]
    }
   ],
   "source": [
    "df.drop(['edit_type_exists'], axis=1, inplace=True)\n",
    "edit_types = [col for col in df.columns if str(col).startswith('edit_type')]\n",
    "print(edit_types)\n",
    "for edit_type in edit_types:\n",
    "    df[edit_type].fillna(value=-1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing threshold > 0\n",
      "[ 0.77669903  0.73786408  0.72815534  0.72815534  0.76470588  0.7254902\n",
      "  0.71287129  0.69306931  0.79207921  0.74257426]\n",
      "Accuracy: 0.740%\n",
      "Precision: 0.735%\n",
      "Recall: 0.751%\n",
      "F1: 0.740%\n",
      "ROC AUC: 0.833%\n",
      "\n",
      "\n",
      "Processing threshold > 1\n",
      "[ 0.66666667  0.71111111  0.77777778  0.71111111  0.73333333  0.77777778\n",
      "  0.71111111  0.73333333  0.69767442  0.8372093 ]\n",
      "Accuracy: 0.736%\n",
      "Precision: 0.750%\n",
      "Recall: 0.798%\n",
      "F1: 0.770%\n",
      "ROC AUC: 0.791%\n",
      "\n",
      "\n",
      "Processing threshold > 2\n",
      "[ 0.6         0.65517241  0.62068966  0.65517241  0.72413793  0.65517241\n",
      "  0.65517241  0.85714286  0.67857143  0.85714286]\n",
      "Accuracy: 0.696%\n",
      "Precision: 0.740%\n",
      "Recall: 0.781%\n",
      "F1: 0.759%\n",
      "ROC AUC: 0.781%\n",
      "\n",
      "\n",
      "Processing threshold > 3\n",
      "[ 0.66666667  0.61904762  0.61904762  0.76190476  0.8         0.8         0.8\n",
      "  0.7         0.65        0.78947368]\n",
      "Accuracy: 0.721%\n",
      "Precision: 0.779%\n",
      "Recall: 0.815%\n",
      "F1: 0.791%\n",
      "ROC AUC: 0.771%\n",
      "\n",
      "\n",
      "Processing threshold > 4\n",
      "[ 0.66666667  0.66666667  0.77777778  0.66666667  0.88235294  0.82352941\n",
      "  0.76470588  0.76470588  0.6875      0.75      ]\n",
      "Accuracy: 0.745%\n",
      "Precision: 0.807%\n",
      "Recall: 0.826%\n",
      "F1: 0.808%\n",
      "ROC AUC: 0.766%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(5)\n",
    "\n",
    "columns = ['Page Edits Threshold', 'Total Examples', 'Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC']\n",
    "rows = []\n",
    "for threshold in thresholds:\n",
    "    print('Processing threshold > {}'.format(threshold))\n",
    "    tmp_df = df[df.page_edits > threshold]\n",
    "    X = tmp_df.drop(__generalized_model_exclusion(), axis=1)\n",
    "    y = tmp_df.label\n",
    "    metrics = get_metrics(classifier=model, x=X, y=y, cv=kfold)\n",
    "    \n",
    "    row = ['page_edits > {}'.format(threshold), len(X)]\n",
    "    for metric in metrics:\n",
    "        row.append(metric)\n",
    "    rows.append(row)\n",
    "\n",
    "model_df = pd.DataFrame(rows, columns=columns)\n",
    "model_df.head()\n",
    "\n",
    "model_df.to_csv(r'data/new_page_edits_threshold_effect.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
